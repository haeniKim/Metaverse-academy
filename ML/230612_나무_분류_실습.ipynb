{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOXjyRdMhQGfTqULmxvpvj+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haeniKim/metaverse-academy/blob/master/ML/230612_%EB%82%98%EB%AC%B4_%EB%B6%84%EB%A5%98_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Practice - Tree"
      ],
      "metadata": {
        "id": "3CFP-a53NEao"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcwdxKTtM2d0"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "\n",
        "covtype = fetch_covtype()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리"
      ],
      "metadata": {
        "id": "6aBMfV98O-aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "dHoXSFaKNZ_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_df = pd.DataFrame(covtype.data,\n",
        "                  columns=[\"x{:02d}\".format(i + 1) for i in range(covtype.data.shape[1])],\n",
        "                  dtype=int)\n",
        "sy = pd.Series(covtype.target, dtype=\"category\")\n",
        "tree_df['covtype'] = sy"
      ],
      "metadata": {
        "id": "6q9kbGgAOvW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "TpsAMQjjPqrR",
        "outputId": "82954376-e041-4042-80ff-b0c71bd3357a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    x01  x02  x03  x04  x05   x06  x07  x08  x09   x10  ...  x46  x47  x48  \\\n",
              "0  2596   51    3  258    0   510  221  232  148  6279  ...    0    0    0   \n",
              "1  2590   56    2  212   -6   390  220  235  151  6225  ...    0    0    0   \n",
              "2  2804  139    9  268   65  3180  234  238  135  6121  ...    0    0    0   \n",
              "3  2785  155   18  242  118  3090  238  238  122  6211  ...    0    0    0   \n",
              "4  2595   45    2  153   -1   391  220  234  150  6172  ...    0    0    0   \n",
              "\n",
              "   x49  x50  x51  x52  x53  x54  covtype  \n",
              "0    0    0    0    0    0    0        5  \n",
              "1    0    0    0    0    0    0        5  \n",
              "2    0    0    0    0    0    0        2  \n",
              "3    0    0    0    0    0    0        2  \n",
              "4    0    0    0    0    0    0        5  \n",
              "\n",
              "[5 rows x 55 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c9e2e38-ed53-4341-80e8-146c6f2c13a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x01</th>\n",
              "      <th>x02</th>\n",
              "      <th>x03</th>\n",
              "      <th>x04</th>\n",
              "      <th>x05</th>\n",
              "      <th>x06</th>\n",
              "      <th>x07</th>\n",
              "      <th>x08</th>\n",
              "      <th>x09</th>\n",
              "      <th>x10</th>\n",
              "      <th>...</th>\n",
              "      <th>x46</th>\n",
              "      <th>x47</th>\n",
              "      <th>x48</th>\n",
              "      <th>x49</th>\n",
              "      <th>x50</th>\n",
              "      <th>x51</th>\n",
              "      <th>x52</th>\n",
              "      <th>x53</th>\n",
              "      <th>x54</th>\n",
              "      <th>covtype</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 55 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c9e2e38-ed53-4341-80e8-146c6f2c13a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c9e2e38-ed53-4341-80e8-146c6f2c13a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c9e2e38-ed53-4341-80e8-146c6f2c13a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgfAW1mGPtPj",
        "outputId": "5122afe0-c6ea-4f32-ad34-5e1d67232a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x01        0\n",
              "x02        0\n",
              "x03        0\n",
              "x04        0\n",
              "x05        0\n",
              "x06        0\n",
              "x07        0\n",
              "x08        0\n",
              "x09        0\n",
              "x10        0\n",
              "x11        0\n",
              "x12        0\n",
              "x13        0\n",
              "x14        0\n",
              "x15        0\n",
              "x16        0\n",
              "x17        0\n",
              "x18        0\n",
              "x19        0\n",
              "x20        0\n",
              "x21        0\n",
              "x22        0\n",
              "x23        0\n",
              "x24        0\n",
              "x25        0\n",
              "x26        0\n",
              "x27        0\n",
              "x28        0\n",
              "x29        0\n",
              "x30        0\n",
              "x31        0\n",
              "x32        0\n",
              "x33        0\n",
              "x34        0\n",
              "x35        0\n",
              "x36        0\n",
              "x37        0\n",
              "x38        0\n",
              "x39        0\n",
              "x40        0\n",
              "x41        0\n",
              "x42        0\n",
              "x43        0\n",
              "x44        0\n",
              "x45        0\n",
              "x46        0\n",
              "x47        0\n",
              "x48        0\n",
              "x49        0\n",
              "x50        0\n",
              "x51        0\n",
              "x52        0\n",
              "x53        0\n",
              "x54        0\n",
              "covtype    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* MinMaxScaler - 정규화 진행"
      ],
      "metadata": {
        "id": "kfd5PYffRyJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X_features = tree_df.iloc[:, :-1]\n",
        "y_labels = tree_df.iloc[:, -1]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_features)\n",
        "tree_ft = scaler.transform(X_features)\n",
        "\n",
        "features_df = pd.DataFrame(data=tree_ft, columns = covtype.feature_names)"
      ],
      "metadata": {
        "id": "TSmiK4BwSHax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_labels.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW5QZcCVYSQv",
        "outputId": "5dafd4a6-b62c-43fc-adf7-2e6c22455151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 2, 1, 7, 3, 6, 4]\n",
              "Categories (7, int64): [1, 2, 3, 4, 5, 6, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "tJJPr8xFTprl",
        "outputId": "5b9d5b04-6eb1-497f-c676-4508b2547782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0   0.368684  0.141667  0.045455                          0.184681   \n",
              "1   0.365683  0.155556  0.030303                          0.151754   \n",
              "2   0.472736  0.386111  0.136364                          0.191840   \n",
              "3   0.463232  0.430556  0.272727                          0.173228   \n",
              "4   0.368184  0.125000  0.030303                          0.109520   \n",
              "\n",
              "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                        0.223514                         0.071659   \n",
              "1                        0.215762                         0.054798   \n",
              "2                        0.307494                         0.446817   \n",
              "3                        0.375969                         0.434172   \n",
              "4                        0.222222                         0.054939   \n",
              "\n",
              "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "0       0.870079        0.913386       0.582677   \n",
              "1       0.866142        0.925197       0.594488   \n",
              "2       0.921260        0.937008       0.531496   \n",
              "3       0.937008        0.937008       0.480315   \n",
              "4       0.866142        0.921260       0.590551   \n",
              "\n",
              "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type_30  Soil_Type_31  \\\n",
              "0                            0.875366  ...           0.0           0.0   \n",
              "1                            0.867838  ...           0.0           0.0   \n",
              "2                            0.853339  ...           0.0           0.0   \n",
              "3                            0.865886  ...           0.0           0.0   \n",
              "4                            0.860449  ...           0.0           0.0   \n",
              "\n",
              "   Soil_Type_32  Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  \\\n",
              "0           0.0           0.0           0.0           0.0           0.0   \n",
              "1           0.0           0.0           0.0           0.0           0.0   \n",
              "2           0.0           0.0           0.0           0.0           0.0   \n",
              "3           0.0           0.0           0.0           0.0           0.0   \n",
              "4           0.0           0.0           0.0           0.0           0.0   \n",
              "\n",
              "   Soil_Type_37  Soil_Type_38  Soil_Type_39  \n",
              "0           0.0           0.0           0.0  \n",
              "1           0.0           0.0           0.0  \n",
              "2           0.0           0.0           0.0  \n",
              "3           0.0           0.0           0.0  \n",
              "4           0.0           0.0           0.0  \n",
              "\n",
              "[5 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5356c81f-6e73-4dcc-876b-3752723b90b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type_30</th>\n",
              "      <th>Soil_Type_31</th>\n",
              "      <th>Soil_Type_32</th>\n",
              "      <th>Soil_Type_33</th>\n",
              "      <th>Soil_Type_34</th>\n",
              "      <th>Soil_Type_35</th>\n",
              "      <th>Soil_Type_36</th>\n",
              "      <th>Soil_Type_37</th>\n",
              "      <th>Soil_Type_38</th>\n",
              "      <th>Soil_Type_39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.368684</td>\n",
              "      <td>0.141667</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.184681</td>\n",
              "      <td>0.223514</td>\n",
              "      <td>0.071659</td>\n",
              "      <td>0.870079</td>\n",
              "      <td>0.913386</td>\n",
              "      <td>0.582677</td>\n",
              "      <td>0.875366</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.365683</td>\n",
              "      <td>0.155556</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.151754</td>\n",
              "      <td>0.215762</td>\n",
              "      <td>0.054798</td>\n",
              "      <td>0.866142</td>\n",
              "      <td>0.925197</td>\n",
              "      <td>0.594488</td>\n",
              "      <td>0.867838</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.472736</td>\n",
              "      <td>0.386111</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.191840</td>\n",
              "      <td>0.307494</td>\n",
              "      <td>0.446817</td>\n",
              "      <td>0.921260</td>\n",
              "      <td>0.937008</td>\n",
              "      <td>0.531496</td>\n",
              "      <td>0.853339</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.463232</td>\n",
              "      <td>0.430556</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.173228</td>\n",
              "      <td>0.375969</td>\n",
              "      <td>0.434172</td>\n",
              "      <td>0.937008</td>\n",
              "      <td>0.937008</td>\n",
              "      <td>0.480315</td>\n",
              "      <td>0.865886</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.368184</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.109520</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.054939</td>\n",
              "      <td>0.866142</td>\n",
              "      <td>0.921260</td>\n",
              "      <td>0.590551</td>\n",
              "      <td>0.860449</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5356c81f-6e73-4dcc-876b-3752723b90b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5356c81f-6e73-4dcc-876b-3752723b90b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5356c81f-6e73-4dcc-876b-3752723b90b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "tree_df['covtype'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iurxknoMP98b",
        "outputId": "9dd0b0a5-160b-4c0c-b20d-a9a6c2a3ee8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    283301\n",
              "1    211840\n",
              "3     35754\n",
              "7     20510\n",
              "6     17367\n",
              "5      9493\n",
              "4      2747\n",
              "Name: covtype, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* train_test_split"
      ],
      "metadata": {
        "id": "Z-0N1ZUnQpl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features_df, y_labels, test_size=0.2 , random_state=100)"
      ],
      "metadata": {
        "id": "edMYbrXuT991"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Oversampling"
      ],
      "metadata": {
        "id": "ItwH2lbMUIBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 분포가 불균형 하므로 Oversampling 진행\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=100)\n",
        "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
        "print('SMOTE 적용 전 데이터 세트: ', X_train.shape, y_train.shape)\n",
        "print('SMOTE 적용 후 데이터 세트: ', X_train_over.shape, y_train_over.shape)\n",
        "print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(y_train_over).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xVOI9UBRANV",
        "outputId": "d9ddd777-e34f-4504-9cec-e2da0cf3a193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMOTE 적용 전 데이터 세트:  (464809, 54) (464809,)\n",
            "SMOTE 적용 후 데이터 세트:  (1586963, 54) (1586963,)\n",
            "SMOTE 적용 후 레이블 값 분포: \n",
            " 1    226709\n",
            "2    226709\n",
            "3    226709\n",
            "4    226709\n",
            "5    226709\n",
            "6    226709\n",
            "7    226709\n",
            "Name: covtype, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습 및 최적화"
      ],
      "metadata": {
        "id": "-kgmj1i2PBZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost 모델 적용"
      ],
      "metadata": {
        "id": "Nq1bS8l6V8z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train_over, y_train_over, test_size = 0.1, random_state=100)"
      ],
      "metadata": {
        "id": "XvqAQUM0PBFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_wrapper = XGBClassifier(n_estimators=400, learning_rate = 0.05, max_depth=3, eval_metric='logloss')\n",
        "\n",
        "xgb_wrapper.fit(X_tr, y_tr, verbose=True)\n",
        "\n",
        "w_preds = xgb_wrapper.predict(X_test)\n",
        "w_pred_proba = xgb_wrapper.predict_proba(X_test)[:,1]"
      ],
      "metadata": {
        "id": "Yv0TVnWQiKGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('정확도 : ', accuracy_score(y_test, w_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnQoPDyhixS1",
        "outputId": "a1ecd85d-226b-480f-c1a3-41f02c12c226"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "정확도 :  0.07045429119730127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(xgb_wrapper, 'xgb_model.pkl')\n",
        "time.sleep(10)\n",
        "files.download('xgb_model.pkl')"
      ],
      "metadata": {
        "id": "Hn9CPLiGwBTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LightGBM"
      ],
      "metadata": {
        "id": "FLIZ6duFdfnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "TA0WpOdqbViD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm_wrapper = LGBMClassifier(n_estimators=400, learning_rate = 0.05)\n",
        "\n",
        "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
        "lgbm_wrapper.fit(X_tr, y_tr, early_stopping_rounds  = 50, eval_metric='logloss',\n",
        "                eval_set=evals, verbose=True)\n",
        "\n",
        "preds = lgbm_wrapper.predict(X_test)\n",
        "pred_proba = lgbm_wrapper.predict_proba(X_test)[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBQFKa3jdh7c",
        "outputId": "8c5caa49-3343-4f23-d0a8-9e5f523d2333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's multi_logloss: 1.7749\tvalid_1's multi_logloss: 1.775\n",
            "[2]\ttraining's multi_logloss: 1.6395\tvalid_1's multi_logloss: 1.63952\n",
            "[3]\ttraining's multi_logloss: 1.52604\tvalid_1's multi_logloss: 1.52613\n",
            "[4]\ttraining's multi_logloss: 1.42979\tvalid_1's multi_logloss: 1.42981\n",
            "[5]\ttraining's multi_logloss: 1.34642\tvalid_1's multi_logloss: 1.34642\n",
            "[6]\ttraining's multi_logloss: 1.27207\tvalid_1's multi_logloss: 1.27205\n",
            "[7]\ttraining's multi_logloss: 1.20612\tvalid_1's multi_logloss: 1.20603\n",
            "[8]\ttraining's multi_logloss: 1.147\tvalid_1's multi_logloss: 1.14691\n",
            "[9]\ttraining's multi_logloss: 1.09361\tvalid_1's multi_logloss: 1.0935\n",
            "[10]\ttraining's multi_logloss: 1.04522\tvalid_1's multi_logloss: 1.04514\n",
            "[11]\ttraining's multi_logloss: 1.00096\tvalid_1's multi_logloss: 1.0008\n",
            "[12]\ttraining's multi_logloss: 0.960887\tvalid_1's multi_logloss: 0.96067\n",
            "[13]\ttraining's multi_logloss: 0.923428\tvalid_1's multi_logloss: 0.923185\n",
            "[14]\ttraining's multi_logloss: 0.889825\tvalid_1's multi_logloss: 0.889594\n",
            "[15]\ttraining's multi_logloss: 0.85855\tvalid_1's multi_logloss: 0.858302\n",
            "[16]\ttraining's multi_logloss: 0.830108\tvalid_1's multi_logloss: 0.829854\n",
            "[17]\ttraining's multi_logloss: 0.803047\tvalid_1's multi_logloss: 0.802777\n",
            "[18]\ttraining's multi_logloss: 0.777878\tvalid_1's multi_logloss: 0.777561\n",
            "[19]\ttraining's multi_logloss: 0.754931\tvalid_1's multi_logloss: 0.754605\n",
            "[20]\ttraining's multi_logloss: 0.733283\tvalid_1's multi_logloss: 0.732987\n",
            "[21]\ttraining's multi_logloss: 0.712936\tvalid_1's multi_logloss: 0.712647\n",
            "[22]\ttraining's multi_logloss: 0.694097\tvalid_1's multi_logloss: 0.693784\n",
            "[23]\ttraining's multi_logloss: 0.67642\tvalid_1's multi_logloss: 0.676103\n",
            "[24]\ttraining's multi_logloss: 0.659764\tvalid_1's multi_logloss: 0.659458\n",
            "[25]\ttraining's multi_logloss: 0.64402\tvalid_1's multi_logloss: 0.643751\n",
            "[26]\ttraining's multi_logloss: 0.629395\tvalid_1's multi_logloss: 0.629122\n",
            "[27]\ttraining's multi_logloss: 0.615522\tvalid_1's multi_logloss: 0.615222\n",
            "[28]\ttraining's multi_logloss: 0.602639\tvalid_1's multi_logloss: 0.602357\n",
            "[29]\ttraining's multi_logloss: 0.590208\tvalid_1's multi_logloss: 0.589964\n",
            "[30]\ttraining's multi_logloss: 0.578757\tvalid_1's multi_logloss: 0.578589\n",
            "[31]\ttraining's multi_logloss: 0.567876\tvalid_1's multi_logloss: 0.567742\n",
            "[32]\ttraining's multi_logloss: 0.557505\tvalid_1's multi_logloss: 0.557381\n",
            "[33]\ttraining's multi_logloss: 0.54777\tvalid_1's multi_logloss: 0.5477\n",
            "[34]\ttraining's multi_logloss: 0.538425\tvalid_1's multi_logloss: 0.538376\n",
            "[35]\ttraining's multi_logloss: 0.529356\tvalid_1's multi_logloss: 0.529372\n",
            "[36]\ttraining's multi_logloss: 0.521025\tvalid_1's multi_logloss: 0.521023\n",
            "[37]\ttraining's multi_logloss: 0.512805\tvalid_1's multi_logloss: 0.512806\n",
            "[38]\ttraining's multi_logloss: 0.504835\tvalid_1's multi_logloss: 0.504868\n",
            "[39]\ttraining's multi_logloss: 0.497074\tvalid_1's multi_logloss: 0.497126\n",
            "[40]\ttraining's multi_logloss: 0.489715\tvalid_1's multi_logloss: 0.489815\n",
            "[41]\ttraining's multi_logloss: 0.482985\tvalid_1's multi_logloss: 0.483114\n",
            "[42]\ttraining's multi_logloss: 0.47639\tvalid_1's multi_logloss: 0.476589\n",
            "[43]\ttraining's multi_logloss: 0.470119\tvalid_1's multi_logloss: 0.470327\n",
            "[44]\ttraining's multi_logloss: 0.464334\tvalid_1's multi_logloss: 0.464615\n",
            "[45]\ttraining's multi_logloss: 0.458573\tvalid_1's multi_logloss: 0.458894\n",
            "[46]\ttraining's multi_logloss: 0.453145\tvalid_1's multi_logloss: 0.453506\n",
            "[47]\ttraining's multi_logloss: 0.448127\tvalid_1's multi_logloss: 0.448539\n",
            "[48]\ttraining's multi_logloss: 0.443232\tvalid_1's multi_logloss: 0.443683\n",
            "[49]\ttraining's multi_logloss: 0.438389\tvalid_1's multi_logloss: 0.438836\n",
            "[50]\ttraining's multi_logloss: 0.433845\tvalid_1's multi_logloss: 0.434263\n",
            "[51]\ttraining's multi_logloss: 0.429273\tvalid_1's multi_logloss: 0.429772\n",
            "[52]\ttraining's multi_logloss: 0.424909\tvalid_1's multi_logloss: 0.42551\n",
            "[53]\ttraining's multi_logloss: 0.420956\tvalid_1's multi_logloss: 0.421555\n",
            "[54]\ttraining's multi_logloss: 0.416828\tvalid_1's multi_logloss: 0.417477\n",
            "[55]\ttraining's multi_logloss: 0.412569\tvalid_1's multi_logloss: 0.413248\n",
            "[56]\ttraining's multi_logloss: 0.408536\tvalid_1's multi_logloss: 0.409254\n",
            "[57]\ttraining's multi_logloss: 0.405067\tvalid_1's multi_logloss: 0.405789\n",
            "[58]\ttraining's multi_logloss: 0.401611\tvalid_1's multi_logloss: 0.402395\n",
            "[59]\ttraining's multi_logloss: 0.398218\tvalid_1's multi_logloss: 0.399045\n",
            "[60]\ttraining's multi_logloss: 0.395033\tvalid_1's multi_logloss: 0.395891\n",
            "[61]\ttraining's multi_logloss: 0.391753\tvalid_1's multi_logloss: 0.392668\n",
            "[62]\ttraining's multi_logloss: 0.388621\tvalid_1's multi_logloss: 0.389529\n",
            "[63]\ttraining's multi_logloss: 0.385451\tvalid_1's multi_logloss: 0.386371\n",
            "[64]\ttraining's multi_logloss: 0.382762\tvalid_1's multi_logloss: 0.383703\n",
            "[65]\ttraining's multi_logloss: 0.3801\tvalid_1's multi_logloss: 0.381093\n",
            "[66]\ttraining's multi_logloss: 0.377129\tvalid_1's multi_logloss: 0.378324\n",
            "[67]\ttraining's multi_logloss: 0.374496\tvalid_1's multi_logloss: 0.375686\n",
            "[68]\ttraining's multi_logloss: 0.372108\tvalid_1's multi_logloss: 0.3733\n",
            "[69]\ttraining's multi_logloss: 0.369473\tvalid_1's multi_logloss: 0.370683\n",
            "[70]\ttraining's multi_logloss: 0.36704\tvalid_1's multi_logloss: 0.368302\n",
            "[71]\ttraining's multi_logloss: 0.364814\tvalid_1's multi_logloss: 0.366125\n",
            "[72]\ttraining's multi_logloss: 0.362607\tvalid_1's multi_logloss: 0.36392\n",
            "[73]\ttraining's multi_logloss: 0.360447\tvalid_1's multi_logloss: 0.361767\n",
            "[74]\ttraining's multi_logloss: 0.358145\tvalid_1's multi_logloss: 0.359489\n",
            "[75]\ttraining's multi_logloss: 0.355859\tvalid_1's multi_logloss: 0.35726\n",
            "[76]\ttraining's multi_logloss: 0.353718\tvalid_1's multi_logloss: 0.35508\n",
            "[77]\ttraining's multi_logloss: 0.351934\tvalid_1's multi_logloss: 0.353298\n",
            "[78]\ttraining's multi_logloss: 0.350025\tvalid_1's multi_logloss: 0.351399\n",
            "[79]\ttraining's multi_logloss: 0.348099\tvalid_1's multi_logloss: 0.349482\n",
            "[80]\ttraining's multi_logloss: 0.346349\tvalid_1's multi_logloss: 0.347766\n",
            "[81]\ttraining's multi_logloss: 0.343906\tvalid_1's multi_logloss: 0.345318\n",
            "[82]\ttraining's multi_logloss: 0.34194\tvalid_1's multi_logloss: 0.343383\n",
            "[83]\ttraining's multi_logloss: 0.340113\tvalid_1's multi_logloss: 0.341581\n",
            "[84]\ttraining's multi_logloss: 0.337874\tvalid_1's multi_logloss: 0.339362\n",
            "[85]\ttraining's multi_logloss: 0.336217\tvalid_1's multi_logloss: 0.337699\n",
            "[86]\ttraining's multi_logloss: 0.33446\tvalid_1's multi_logloss: 0.335975\n",
            "[87]\ttraining's multi_logloss: 0.332407\tvalid_1's multi_logloss: 0.33395\n",
            "[88]\ttraining's multi_logloss: 0.330723\tvalid_1's multi_logloss: 0.332277\n",
            "[89]\ttraining's multi_logloss: 0.32915\tvalid_1's multi_logloss: 0.330686\n",
            "[90]\ttraining's multi_logloss: 0.32702\tvalid_1's multi_logloss: 0.328564\n",
            "[91]\ttraining's multi_logloss: 0.325551\tvalid_1's multi_logloss: 0.327084\n",
            "[92]\ttraining's multi_logloss: 0.324294\tvalid_1's multi_logloss: 0.325825\n",
            "[93]\ttraining's multi_logloss: 0.322316\tvalid_1's multi_logloss: 0.323889\n",
            "[94]\ttraining's multi_logloss: 0.320939\tvalid_1's multi_logloss: 0.32253\n",
            "[95]\ttraining's multi_logloss: 0.319513\tvalid_1's multi_logloss: 0.321106\n",
            "[96]\ttraining's multi_logloss: 0.31815\tvalid_1's multi_logloss: 0.319755\n",
            "[97]\ttraining's multi_logloss: 0.316598\tvalid_1's multi_logloss: 0.318251\n",
            "[98]\ttraining's multi_logloss: 0.314851\tvalid_1's multi_logloss: 0.316511\n",
            "[99]\ttraining's multi_logloss: 0.313365\tvalid_1's multi_logloss: 0.315061\n",
            "[100]\ttraining's multi_logloss: 0.312143\tvalid_1's multi_logloss: 0.313871\n",
            "[101]\ttraining's multi_logloss: 0.310917\tvalid_1's multi_logloss: 0.312649\n",
            "[102]\ttraining's multi_logloss: 0.309719\tvalid_1's multi_logloss: 0.311451\n",
            "[103]\ttraining's multi_logloss: 0.30848\tvalid_1's multi_logloss: 0.310224\n",
            "[104]\ttraining's multi_logloss: 0.306639\tvalid_1's multi_logloss: 0.308406\n",
            "[105]\ttraining's multi_logloss: 0.305443\tvalid_1's multi_logloss: 0.307214\n",
            "[106]\ttraining's multi_logloss: 0.304207\tvalid_1's multi_logloss: 0.305991\n",
            "[107]\ttraining's multi_logloss: 0.303145\tvalid_1's multi_logloss: 0.304946\n",
            "[108]\ttraining's multi_logloss: 0.302082\tvalid_1's multi_logloss: 0.303885\n",
            "[109]\ttraining's multi_logloss: 0.300342\tvalid_1's multi_logloss: 0.302132\n",
            "[110]\ttraining's multi_logloss: 0.299144\tvalid_1's multi_logloss: 0.300952\n",
            "[111]\ttraining's multi_logloss: 0.298022\tvalid_1's multi_logloss: 0.299821\n",
            "[112]\ttraining's multi_logloss: 0.296917\tvalid_1's multi_logloss: 0.298734\n",
            "[113]\ttraining's multi_logloss: 0.295892\tvalid_1's multi_logloss: 0.297752\n",
            "[114]\ttraining's multi_logloss: 0.294569\tvalid_1's multi_logloss: 0.296408\n",
            "[115]\ttraining's multi_logloss: 0.29332\tvalid_1's multi_logloss: 0.295169\n",
            "[116]\ttraining's multi_logloss: 0.291922\tvalid_1's multi_logloss: 0.293759\n",
            "[117]\ttraining's multi_logloss: 0.290888\tvalid_1's multi_logloss: 0.292705\n",
            "[118]\ttraining's multi_logloss: 0.289567\tvalid_1's multi_logloss: 0.2914\n",
            "[119]\ttraining's multi_logloss: 0.288433\tvalid_1's multi_logloss: 0.290283\n",
            "[120]\ttraining's multi_logloss: 0.287206\tvalid_1's multi_logloss: 0.28907\n",
            "[121]\ttraining's multi_logloss: 0.28632\tvalid_1's multi_logloss: 0.288214\n",
            "[122]\ttraining's multi_logloss: 0.284931\tvalid_1's multi_logloss: 0.286827\n",
            "[123]\ttraining's multi_logloss: 0.283801\tvalid_1's multi_logloss: 0.285717\n",
            "[124]\ttraining's multi_logloss: 0.282915\tvalid_1's multi_logloss: 0.284855\n",
            "[125]\ttraining's multi_logloss: 0.281898\tvalid_1's multi_logloss: 0.283802\n",
            "[126]\ttraining's multi_logloss: 0.280804\tvalid_1's multi_logloss: 0.28271\n",
            "[127]\ttraining's multi_logloss: 0.27949\tvalid_1's multi_logloss: 0.281395\n",
            "[128]\ttraining's multi_logloss: 0.278455\tvalid_1's multi_logloss: 0.280373\n",
            "[129]\ttraining's multi_logloss: 0.277651\tvalid_1's multi_logloss: 0.279552\n",
            "[130]\ttraining's multi_logloss: 0.276597\tvalid_1's multi_logloss: 0.278511\n",
            "[131]\ttraining's multi_logloss: 0.275478\tvalid_1's multi_logloss: 0.277372\n",
            "[132]\ttraining's multi_logloss: 0.274349\tvalid_1's multi_logloss: 0.276252\n",
            "[133]\ttraining's multi_logloss: 0.27344\tvalid_1's multi_logloss: 0.275331\n",
            "[134]\ttraining's multi_logloss: 0.272682\tvalid_1's multi_logloss: 0.274586\n",
            "[135]\ttraining's multi_logloss: 0.271805\tvalid_1's multi_logloss: 0.27374\n",
            "[136]\ttraining's multi_logloss: 0.270709\tvalid_1's multi_logloss: 0.272651\n",
            "[137]\ttraining's multi_logloss: 0.269956\tvalid_1's multi_logloss: 0.271896\n",
            "[138]\ttraining's multi_logloss: 0.269108\tvalid_1's multi_logloss: 0.271087\n",
            "[139]\ttraining's multi_logloss: 0.268208\tvalid_1's multi_logloss: 0.270176\n",
            "[140]\ttraining's multi_logloss: 0.267461\tvalid_1's multi_logloss: 0.269448\n",
            "[141]\ttraining's multi_logloss: 0.266463\tvalid_1's multi_logloss: 0.268474\n",
            "[142]\ttraining's multi_logloss: 0.265747\tvalid_1's multi_logloss: 0.267779\n",
            "[143]\ttraining's multi_logloss: 0.264946\tvalid_1's multi_logloss: 0.266988\n",
            "[144]\ttraining's multi_logloss: 0.264221\tvalid_1's multi_logloss: 0.266293\n",
            "[145]\ttraining's multi_logloss: 0.263196\tvalid_1's multi_logloss: 0.265301\n",
            "[146]\ttraining's multi_logloss: 0.262167\tvalid_1's multi_logloss: 0.264276\n",
            "[147]\ttraining's multi_logloss: 0.261181\tvalid_1's multi_logloss: 0.26329\n",
            "[148]\ttraining's multi_logloss: 0.260493\tvalid_1's multi_logloss: 0.262628\n",
            "[149]\ttraining's multi_logloss: 0.259602\tvalid_1's multi_logloss: 0.261749\n",
            "[150]\ttraining's multi_logloss: 0.258888\tvalid_1's multi_logloss: 0.261049\n",
            "[151]\ttraining's multi_logloss: 0.258095\tvalid_1's multi_logloss: 0.26026\n",
            "[152]\ttraining's multi_logloss: 0.257439\tvalid_1's multi_logloss: 0.25962\n",
            "[153]\ttraining's multi_logloss: 0.256464\tvalid_1's multi_logloss: 0.258645\n",
            "[154]\ttraining's multi_logloss: 0.255593\tvalid_1's multi_logloss: 0.257781\n",
            "[155]\ttraining's multi_logloss: 0.254963\tvalid_1's multi_logloss: 0.257156\n",
            "[156]\ttraining's multi_logloss: 0.254252\tvalid_1's multi_logloss: 0.256441\n",
            "[157]\ttraining's multi_logloss: 0.253527\tvalid_1's multi_logloss: 0.255721\n",
            "[158]\ttraining's multi_logloss: 0.25254\tvalid_1's multi_logloss: 0.254755\n",
            "[159]\ttraining's multi_logloss: 0.251879\tvalid_1's multi_logloss: 0.254109\n",
            "[160]\ttraining's multi_logloss: 0.251007\tvalid_1's multi_logloss: 0.253236\n",
            "[161]\ttraining's multi_logloss: 0.250268\tvalid_1's multi_logloss: 0.252516\n",
            "[162]\ttraining's multi_logloss: 0.24959\tvalid_1's multi_logloss: 0.251868\n",
            "[163]\ttraining's multi_logloss: 0.248742\tvalid_1's multi_logloss: 0.251027\n",
            "[164]\ttraining's multi_logloss: 0.247961\tvalid_1's multi_logloss: 0.250256\n",
            "[165]\ttraining's multi_logloss: 0.246917\tvalid_1's multi_logloss: 0.249212\n",
            "[166]\ttraining's multi_logloss: 0.246049\tvalid_1's multi_logloss: 0.248342\n",
            "[167]\ttraining's multi_logloss: 0.245299\tvalid_1's multi_logloss: 0.247641\n",
            "[168]\ttraining's multi_logloss: 0.244615\tvalid_1's multi_logloss: 0.247002\n",
            "[169]\ttraining's multi_logloss: 0.244019\tvalid_1's multi_logloss: 0.246416\n",
            "[170]\ttraining's multi_logloss: 0.24334\tvalid_1's multi_logloss: 0.245756\n",
            "[171]\ttraining's multi_logloss: 0.242526\tvalid_1's multi_logloss: 0.244947\n",
            "[172]\ttraining's multi_logloss: 0.241935\tvalid_1's multi_logloss: 0.244359\n",
            "[173]\ttraining's multi_logloss: 0.24124\tvalid_1's multi_logloss: 0.24367\n",
            "[174]\ttraining's multi_logloss: 0.240537\tvalid_1's multi_logloss: 0.243025\n",
            "[175]\ttraining's multi_logloss: 0.239849\tvalid_1's multi_logloss: 0.242368\n",
            "[176]\ttraining's multi_logloss: 0.239174\tvalid_1's multi_logloss: 0.24171\n",
            "[177]\ttraining's multi_logloss: 0.238359\tvalid_1's multi_logloss: 0.240898\n",
            "[178]\ttraining's multi_logloss: 0.237817\tvalid_1's multi_logloss: 0.24037\n",
            "[179]\ttraining's multi_logloss: 0.237212\tvalid_1's multi_logloss: 0.239768\n",
            "[180]\ttraining's multi_logloss: 0.236625\tvalid_1's multi_logloss: 0.239187\n",
            "[181]\ttraining's multi_logloss: 0.236056\tvalid_1's multi_logloss: 0.238626\n",
            "[182]\ttraining's multi_logloss: 0.235302\tvalid_1's multi_logloss: 0.237883\n",
            "[183]\ttraining's multi_logloss: 0.234582\tvalid_1's multi_logloss: 0.237176\n",
            "[184]\ttraining's multi_logloss: 0.233919\tvalid_1's multi_logloss: 0.236549\n",
            "[185]\ttraining's multi_logloss: 0.233313\tvalid_1's multi_logloss: 0.235944\n",
            "[186]\ttraining's multi_logloss: 0.232688\tvalid_1's multi_logloss: 0.235326\n",
            "[187]\ttraining's multi_logloss: 0.232145\tvalid_1's multi_logloss: 0.234787\n",
            "[188]\ttraining's multi_logloss: 0.231553\tvalid_1's multi_logloss: 0.234212\n",
            "[189]\ttraining's multi_logloss: 0.230808\tvalid_1's multi_logloss: 0.233493\n",
            "[190]\ttraining's multi_logloss: 0.230192\tvalid_1's multi_logloss: 0.232897\n",
            "[191]\ttraining's multi_logloss: 0.229706\tvalid_1's multi_logloss: 0.232425\n",
            "[192]\ttraining's multi_logloss: 0.229261\tvalid_1's multi_logloss: 0.232\n",
            "[193]\ttraining's multi_logloss: 0.228601\tvalid_1's multi_logloss: 0.231355\n",
            "[194]\ttraining's multi_logloss: 0.228065\tvalid_1's multi_logloss: 0.230823\n",
            "[195]\ttraining's multi_logloss: 0.227428\tvalid_1's multi_logloss: 0.230207\n",
            "[196]\ttraining's multi_logloss: 0.226846\tvalid_1's multi_logloss: 0.229622\n",
            "[197]\ttraining's multi_logloss: 0.226133\tvalid_1's multi_logloss: 0.228906\n",
            "[198]\ttraining's multi_logloss: 0.225468\tvalid_1's multi_logloss: 0.228252\n",
            "[199]\ttraining's multi_logloss: 0.224856\tvalid_1's multi_logloss: 0.22764\n",
            "[200]\ttraining's multi_logloss: 0.224343\tvalid_1's multi_logloss: 0.227122\n",
            "[201]\ttraining's multi_logloss: 0.223838\tvalid_1's multi_logloss: 0.226629\n",
            "[202]\ttraining's multi_logloss: 0.2232\tvalid_1's multi_logloss: 0.226034\n",
            "[203]\ttraining's multi_logloss: 0.222568\tvalid_1's multi_logloss: 0.225428\n",
            "[204]\ttraining's multi_logloss: 0.222027\tvalid_1's multi_logloss: 0.224905\n",
            "[205]\ttraining's multi_logloss: 0.221435\tvalid_1's multi_logloss: 0.224305\n",
            "[206]\ttraining's multi_logloss: 0.220886\tvalid_1's multi_logloss: 0.223777\n",
            "[207]\ttraining's multi_logloss: 0.220179\tvalid_1's multi_logloss: 0.223085\n",
            "[208]\ttraining's multi_logloss: 0.219456\tvalid_1's multi_logloss: 0.222378\n",
            "[209]\ttraining's multi_logloss: 0.218979\tvalid_1's multi_logloss: 0.221907\n",
            "[210]\ttraining's multi_logloss: 0.218346\tvalid_1's multi_logloss: 0.221287\n",
            "[211]\ttraining's multi_logloss: 0.217877\tvalid_1's multi_logloss: 0.220868\n",
            "[212]\ttraining's multi_logloss: 0.217367\tvalid_1's multi_logloss: 0.220356\n",
            "[213]\ttraining's multi_logloss: 0.216724\tvalid_1's multi_logloss: 0.219739\n",
            "[214]\ttraining's multi_logloss: 0.215968\tvalid_1's multi_logloss: 0.218995\n",
            "[215]\ttraining's multi_logloss: 0.215388\tvalid_1's multi_logloss: 0.218413\n",
            "[216]\ttraining's multi_logloss: 0.214831\tvalid_1's multi_logloss: 0.217869\n",
            "[217]\ttraining's multi_logloss: 0.214272\tvalid_1's multi_logloss: 0.217311\n",
            "[218]\ttraining's multi_logloss: 0.21358\tvalid_1's multi_logloss: 0.216633\n",
            "[219]\ttraining's multi_logloss: 0.213133\tvalid_1's multi_logloss: 0.216206\n",
            "[220]\ttraining's multi_logloss: 0.212558\tvalid_1's multi_logloss: 0.215633\n",
            "[221]\ttraining's multi_logloss: 0.212086\tvalid_1's multi_logloss: 0.215183\n",
            "[222]\ttraining's multi_logloss: 0.21149\tvalid_1's multi_logloss: 0.214608\n",
            "[223]\ttraining's multi_logloss: 0.210786\tvalid_1's multi_logloss: 0.213909\n",
            "[224]\ttraining's multi_logloss: 0.210277\tvalid_1's multi_logloss: 0.213412\n",
            "[225]\ttraining's multi_logloss: 0.209703\tvalid_1's multi_logloss: 0.212834\n",
            "[226]\ttraining's multi_logloss: 0.209086\tvalid_1's multi_logloss: 0.212209\n",
            "[227]\ttraining's multi_logloss: 0.208488\tvalid_1's multi_logloss: 0.211639\n",
            "[228]\ttraining's multi_logloss: 0.20795\tvalid_1's multi_logloss: 0.211118\n",
            "[229]\ttraining's multi_logloss: 0.207325\tvalid_1's multi_logloss: 0.210507\n",
            "[230]\ttraining's multi_logloss: 0.206871\tvalid_1's multi_logloss: 0.210068\n",
            "[231]\ttraining's multi_logloss: 0.20645\tvalid_1's multi_logloss: 0.209659\n",
            "[232]\ttraining's multi_logloss: 0.206032\tvalid_1's multi_logloss: 0.209278\n",
            "[233]\ttraining's multi_logloss: 0.205531\tvalid_1's multi_logloss: 0.208797\n",
            "[234]\ttraining's multi_logloss: 0.205131\tvalid_1's multi_logloss: 0.208413\n",
            "[235]\ttraining's multi_logloss: 0.204733\tvalid_1's multi_logloss: 0.208012\n",
            "[236]\ttraining's multi_logloss: 0.204313\tvalid_1's multi_logloss: 0.207586\n",
            "[237]\ttraining's multi_logloss: 0.203786\tvalid_1's multi_logloss: 0.207083\n",
            "[238]\ttraining's multi_logloss: 0.203377\tvalid_1's multi_logloss: 0.206698\n",
            "[239]\ttraining's multi_logloss: 0.202864\tvalid_1's multi_logloss: 0.206203\n",
            "[240]\ttraining's multi_logloss: 0.20236\tvalid_1's multi_logloss: 0.205711\n",
            "[241]\ttraining's multi_logloss: 0.201882\tvalid_1's multi_logloss: 0.205248\n",
            "[242]\ttraining's multi_logloss: 0.201386\tvalid_1's multi_logloss: 0.204754\n",
            "[243]\ttraining's multi_logloss: 0.200969\tvalid_1's multi_logloss: 0.204351\n",
            "[244]\ttraining's multi_logloss: 0.200517\tvalid_1's multi_logloss: 0.203909\n",
            "[245]\ttraining's multi_logloss: 0.200074\tvalid_1's multi_logloss: 0.203463\n",
            "[246]\ttraining's multi_logloss: 0.199653\tvalid_1's multi_logloss: 0.203052\n",
            "[247]\ttraining's multi_logloss: 0.199131\tvalid_1's multi_logloss: 0.202553\n",
            "[248]\ttraining's multi_logloss: 0.198705\tvalid_1's multi_logloss: 0.202149\n",
            "[249]\ttraining's multi_logloss: 0.19828\tvalid_1's multi_logloss: 0.201725\n",
            "[250]\ttraining's multi_logloss: 0.197843\tvalid_1's multi_logloss: 0.20131\n",
            "[251]\ttraining's multi_logloss: 0.197355\tvalid_1's multi_logloss: 0.200832\n",
            "[252]\ttraining's multi_logloss: 0.19683\tvalid_1's multi_logloss: 0.200314\n",
            "[253]\ttraining's multi_logloss: 0.196465\tvalid_1's multi_logloss: 0.199954\n",
            "[254]\ttraining's multi_logloss: 0.19594\tvalid_1's multi_logloss: 0.199472\n",
            "[255]\ttraining's multi_logloss: 0.19559\tvalid_1's multi_logloss: 0.199131\n",
            "[256]\ttraining's multi_logloss: 0.195144\tvalid_1's multi_logloss: 0.198692\n",
            "[257]\ttraining's multi_logloss: 0.194718\tvalid_1's multi_logloss: 0.198272\n",
            "[258]\ttraining's multi_logloss: 0.194277\tvalid_1's multi_logloss: 0.197845\n",
            "[259]\ttraining's multi_logloss: 0.193933\tvalid_1's multi_logloss: 0.197517\n",
            "[260]\ttraining's multi_logloss: 0.193487\tvalid_1's multi_logloss: 0.197086\n",
            "[261]\ttraining's multi_logloss: 0.193072\tvalid_1's multi_logloss: 0.196679\n",
            "[262]\ttraining's multi_logloss: 0.192581\tvalid_1's multi_logloss: 0.196211\n",
            "[263]\ttraining's multi_logloss: 0.192216\tvalid_1's multi_logloss: 0.195861\n",
            "[264]\ttraining's multi_logloss: 0.191739\tvalid_1's multi_logloss: 0.195398\n",
            "[265]\ttraining's multi_logloss: 0.191305\tvalid_1's multi_logloss: 0.19497\n",
            "[266]\ttraining's multi_logloss: 0.190859\tvalid_1's multi_logloss: 0.194532\n",
            "[267]\ttraining's multi_logloss: 0.190492\tvalid_1's multi_logloss: 0.194177\n",
            "[268]\ttraining's multi_logloss: 0.19008\tvalid_1's multi_logloss: 0.193783\n",
            "[269]\ttraining's multi_logloss: 0.189744\tvalid_1's multi_logloss: 0.193448\n",
            "[270]\ttraining's multi_logloss: 0.189294\tvalid_1's multi_logloss: 0.193001\n",
            "[271]\ttraining's multi_logloss: 0.188956\tvalid_1's multi_logloss: 0.192667\n",
            "[272]\ttraining's multi_logloss: 0.18857\tvalid_1's multi_logloss: 0.19228\n",
            "[273]\ttraining's multi_logloss: 0.188235\tvalid_1's multi_logloss: 0.191953\n",
            "[274]\ttraining's multi_logloss: 0.187877\tvalid_1's multi_logloss: 0.191593\n",
            "[275]\ttraining's multi_logloss: 0.187441\tvalid_1's multi_logloss: 0.191157\n",
            "[276]\ttraining's multi_logloss: 0.187086\tvalid_1's multi_logloss: 0.190809\n",
            "[277]\ttraining's multi_logloss: 0.186736\tvalid_1's multi_logloss: 0.190486\n",
            "[278]\ttraining's multi_logloss: 0.186326\tvalid_1's multi_logloss: 0.190076\n",
            "[279]\ttraining's multi_logloss: 0.185937\tvalid_1's multi_logloss: 0.189694\n",
            "[280]\ttraining's multi_logloss: 0.185624\tvalid_1's multi_logloss: 0.189394\n",
            "[281]\ttraining's multi_logloss: 0.185124\tvalid_1's multi_logloss: 0.188877\n",
            "[282]\ttraining's multi_logloss: 0.184868\tvalid_1's multi_logloss: 0.188623\n",
            "[283]\ttraining's multi_logloss: 0.18457\tvalid_1's multi_logloss: 0.188325\n",
            "[284]\ttraining's multi_logloss: 0.184253\tvalid_1's multi_logloss: 0.188017\n",
            "[285]\ttraining's multi_logloss: 0.183972\tvalid_1's multi_logloss: 0.187745\n",
            "[286]\ttraining's multi_logloss: 0.1836\tvalid_1's multi_logloss: 0.187372\n",
            "[287]\ttraining's multi_logloss: 0.183231\tvalid_1's multi_logloss: 0.187007\n",
            "[288]\ttraining's multi_logloss: 0.182908\tvalid_1's multi_logloss: 0.186684\n",
            "[289]\ttraining's multi_logloss: 0.182539\tvalid_1's multi_logloss: 0.186335\n",
            "[290]\ttraining's multi_logloss: 0.182057\tvalid_1's multi_logloss: 0.185869\n",
            "[291]\ttraining's multi_logloss: 0.181649\tvalid_1's multi_logloss: 0.18545\n",
            "[292]\ttraining's multi_logloss: 0.181218\tvalid_1's multi_logloss: 0.185027\n",
            "[293]\ttraining's multi_logloss: 0.18089\tvalid_1's multi_logloss: 0.184702\n",
            "[294]\ttraining's multi_logloss: 0.180601\tvalid_1's multi_logloss: 0.184422\n",
            "[295]\ttraining's multi_logloss: 0.180251\tvalid_1's multi_logloss: 0.184079\n",
            "[296]\ttraining's multi_logloss: 0.179942\tvalid_1's multi_logloss: 0.183779\n",
            "[297]\ttraining's multi_logloss: 0.179614\tvalid_1's multi_logloss: 0.183454\n",
            "[298]\ttraining's multi_logloss: 0.179223\tvalid_1's multi_logloss: 0.183081\n",
            "[299]\ttraining's multi_logloss: 0.178918\tvalid_1's multi_logloss: 0.182786\n",
            "[300]\ttraining's multi_logloss: 0.178575\tvalid_1's multi_logloss: 0.182449\n",
            "[301]\ttraining's multi_logloss: 0.178255\tvalid_1's multi_logloss: 0.182135\n",
            "[302]\ttraining's multi_logloss: 0.177934\tvalid_1's multi_logloss: 0.181819\n",
            "[303]\ttraining's multi_logloss: 0.177622\tvalid_1's multi_logloss: 0.181526\n",
            "[304]\ttraining's multi_logloss: 0.177292\tvalid_1's multi_logloss: 0.181219\n",
            "[305]\ttraining's multi_logloss: 0.176962\tvalid_1's multi_logloss: 0.18089\n",
            "[306]\ttraining's multi_logloss: 0.176642\tvalid_1's multi_logloss: 0.180571\n",
            "[307]\ttraining's multi_logloss: 0.17636\tvalid_1's multi_logloss: 0.180296\n",
            "[308]\ttraining's multi_logloss: 0.176071\tvalid_1's multi_logloss: 0.180011\n",
            "[309]\ttraining's multi_logloss: 0.17578\tvalid_1's multi_logloss: 0.17972\n",
            "[310]\ttraining's multi_logloss: 0.175283\tvalid_1's multi_logloss: 0.17923\n",
            "[311]\ttraining's multi_logloss: 0.174891\tvalid_1's multi_logloss: 0.178839\n",
            "[312]\ttraining's multi_logloss: 0.174581\tvalid_1's multi_logloss: 0.178523\n",
            "[313]\ttraining's multi_logloss: 0.174285\tvalid_1's multi_logloss: 0.178235\n",
            "[314]\ttraining's multi_logloss: 0.17392\tvalid_1's multi_logloss: 0.177887\n",
            "[315]\ttraining's multi_logloss: 0.173566\tvalid_1's multi_logloss: 0.177548\n",
            "[316]\ttraining's multi_logloss: 0.173256\tvalid_1's multi_logloss: 0.177247\n",
            "[317]\ttraining's multi_logloss: 0.172957\tvalid_1's multi_logloss: 0.176958\n",
            "[318]\ttraining's multi_logloss: 0.172635\tvalid_1's multi_logloss: 0.176644\n",
            "[319]\ttraining's multi_logloss: 0.1724\tvalid_1's multi_logloss: 0.176416\n",
            "[320]\ttraining's multi_logloss: 0.172186\tvalid_1's multi_logloss: 0.176212\n",
            "[321]\ttraining's multi_logloss: 0.171767\tvalid_1's multi_logloss: 0.175808\n",
            "[322]\ttraining's multi_logloss: 0.171491\tvalid_1's multi_logloss: 0.175524\n",
            "[323]\ttraining's multi_logloss: 0.171177\tvalid_1's multi_logloss: 0.175234\n",
            "[324]\ttraining's multi_logloss: 0.170851\tvalid_1's multi_logloss: 0.174909\n",
            "[325]\ttraining's multi_logloss: 0.170597\tvalid_1's multi_logloss: 0.174671\n",
            "[326]\ttraining's multi_logloss: 0.170241\tvalid_1's multi_logloss: 0.174321\n",
            "[327]\ttraining's multi_logloss: 0.169921\tvalid_1's multi_logloss: 0.174007\n",
            "[328]\ttraining's multi_logloss: 0.169695\tvalid_1's multi_logloss: 0.173782\n",
            "[329]\ttraining's multi_logloss: 0.169398\tvalid_1's multi_logloss: 0.173493\n",
            "[330]\ttraining's multi_logloss: 0.169019\tvalid_1's multi_logloss: 0.173128\n",
            "[331]\ttraining's multi_logloss: 0.168785\tvalid_1's multi_logloss: 0.172897\n",
            "[332]\ttraining's multi_logloss: 0.168464\tvalid_1's multi_logloss: 0.172583\n",
            "[333]\ttraining's multi_logloss: 0.168223\tvalid_1's multi_logloss: 0.172358\n",
            "[334]\ttraining's multi_logloss: 0.167911\tvalid_1's multi_logloss: 0.172048\n",
            "[335]\ttraining's multi_logloss: 0.167605\tvalid_1's multi_logloss: 0.171745\n",
            "[336]\ttraining's multi_logloss: 0.167306\tvalid_1's multi_logloss: 0.171443\n",
            "[337]\ttraining's multi_logloss: 0.166994\tvalid_1's multi_logloss: 0.171146\n",
            "[338]\ttraining's multi_logloss: 0.166729\tvalid_1's multi_logloss: 0.170895\n",
            "[339]\ttraining's multi_logloss: 0.166524\tvalid_1's multi_logloss: 0.170685\n",
            "[340]\ttraining's multi_logloss: 0.166189\tvalid_1's multi_logloss: 0.17034\n",
            "[341]\ttraining's multi_logloss: 0.165852\tvalid_1's multi_logloss: 0.170014\n",
            "[342]\ttraining's multi_logloss: 0.165605\tvalid_1's multi_logloss: 0.169774\n",
            "[343]\ttraining's multi_logloss: 0.165244\tvalid_1's multi_logloss: 0.169423\n",
            "[344]\ttraining's multi_logloss: 0.16501\tvalid_1's multi_logloss: 0.169198\n",
            "[345]\ttraining's multi_logloss: 0.164822\tvalid_1's multi_logloss: 0.16901\n",
            "[346]\ttraining's multi_logloss: 0.16452\tvalid_1's multi_logloss: 0.168713\n",
            "[347]\ttraining's multi_logloss: 0.164258\tvalid_1's multi_logloss: 0.168442\n",
            "[348]\ttraining's multi_logloss: 0.163954\tvalid_1's multi_logloss: 0.168141\n",
            "[349]\ttraining's multi_logloss: 0.163714\tvalid_1's multi_logloss: 0.167909\n",
            "[350]\ttraining's multi_logloss: 0.163426\tvalid_1's multi_logloss: 0.167617\n",
            "[351]\ttraining's multi_logloss: 0.163159\tvalid_1's multi_logloss: 0.167352\n",
            "[352]\ttraining's multi_logloss: 0.16293\tvalid_1's multi_logloss: 0.167117\n",
            "[353]\ttraining's multi_logloss: 0.162728\tvalid_1's multi_logloss: 0.166919\n",
            "[354]\ttraining's multi_logloss: 0.162459\tvalid_1's multi_logloss: 0.166655\n",
            "[355]\ttraining's multi_logloss: 0.162158\tvalid_1's multi_logloss: 0.166365\n",
            "[356]\ttraining's multi_logloss: 0.161915\tvalid_1's multi_logloss: 0.166116\n",
            "[357]\ttraining's multi_logloss: 0.161637\tvalid_1's multi_logloss: 0.165843\n",
            "[358]\ttraining's multi_logloss: 0.16136\tvalid_1's multi_logloss: 0.165577\n",
            "[359]\ttraining's multi_logloss: 0.161109\tvalid_1's multi_logloss: 0.165336\n",
            "[360]\ttraining's multi_logloss: 0.160851\tvalid_1's multi_logloss: 0.165075\n",
            "[361]\ttraining's multi_logloss: 0.160585\tvalid_1's multi_logloss: 0.164816\n",
            "[362]\ttraining's multi_logloss: 0.160366\tvalid_1's multi_logloss: 0.164615\n",
            "[363]\ttraining's multi_logloss: 0.160076\tvalid_1's multi_logloss: 0.164333\n",
            "[364]\ttraining's multi_logloss: 0.159842\tvalid_1's multi_logloss: 0.164109\n",
            "[365]\ttraining's multi_logloss: 0.159573\tvalid_1's multi_logloss: 0.163837\n",
            "[366]\ttraining's multi_logloss: 0.159395\tvalid_1's multi_logloss: 0.163671\n",
            "[367]\ttraining's multi_logloss: 0.159092\tvalid_1's multi_logloss: 0.163374\n",
            "[368]\ttraining's multi_logloss: 0.158781\tvalid_1's multi_logloss: 0.163071\n",
            "[369]\ttraining's multi_logloss: 0.158539\tvalid_1's multi_logloss: 0.162833\n",
            "[370]\ttraining's multi_logloss: 0.158309\tvalid_1's multi_logloss: 0.162607\n",
            "[371]\ttraining's multi_logloss: 0.158014\tvalid_1's multi_logloss: 0.162306\n",
            "[372]\ttraining's multi_logloss: 0.157783\tvalid_1's multi_logloss: 0.162077\n",
            "[373]\ttraining's multi_logloss: 0.1575\tvalid_1's multi_logloss: 0.161796\n",
            "[374]\ttraining's multi_logloss: 0.157225\tvalid_1's multi_logloss: 0.161518\n",
            "[375]\ttraining's multi_logloss: 0.156947\tvalid_1's multi_logloss: 0.161236\n",
            "[376]\ttraining's multi_logloss: 0.156711\tvalid_1's multi_logloss: 0.161006\n",
            "[377]\ttraining's multi_logloss: 0.156398\tvalid_1's multi_logloss: 0.160681\n",
            "[378]\ttraining's multi_logloss: 0.156136\tvalid_1's multi_logloss: 0.160421\n",
            "[379]\ttraining's multi_logloss: 0.155972\tvalid_1's multi_logloss: 0.160267\n",
            "[380]\ttraining's multi_logloss: 0.155702\tvalid_1's multi_logloss: 0.160041\n",
            "[381]\ttraining's multi_logloss: 0.155475\tvalid_1's multi_logloss: 0.159812\n",
            "[382]\ttraining's multi_logloss: 0.155224\tvalid_1's multi_logloss: 0.159577\n",
            "[383]\ttraining's multi_logloss: 0.154959\tvalid_1's multi_logloss: 0.159315\n",
            "[384]\ttraining's multi_logloss: 0.154793\tvalid_1's multi_logloss: 0.159159\n",
            "[385]\ttraining's multi_logloss: 0.154537\tvalid_1's multi_logloss: 0.158915\n",
            "[386]\ttraining's multi_logloss: 0.154301\tvalid_1's multi_logloss: 0.158694\n",
            "[387]\ttraining's multi_logloss: 0.154038\tvalid_1's multi_logloss: 0.158429\n",
            "[388]\ttraining's multi_logloss: 0.153859\tvalid_1's multi_logloss: 0.158253\n",
            "[389]\ttraining's multi_logloss: 0.153704\tvalid_1's multi_logloss: 0.158098\n",
            "[390]\ttraining's multi_logloss: 0.153419\tvalid_1's multi_logloss: 0.157823\n",
            "[391]\ttraining's multi_logloss: 0.153251\tvalid_1's multi_logloss: 0.157671\n",
            "[392]\ttraining's multi_logloss: 0.152982\tvalid_1's multi_logloss: 0.157406\n",
            "[393]\ttraining's multi_logloss: 0.152788\tvalid_1's multi_logloss: 0.157223\n",
            "[394]\ttraining's multi_logloss: 0.152585\tvalid_1's multi_logloss: 0.157029\n",
            "[395]\ttraining's multi_logloss: 0.15242\tvalid_1's multi_logloss: 0.156868\n",
            "[396]\ttraining's multi_logloss: 0.152246\tvalid_1's multi_logloss: 0.156703\n",
            "[397]\ttraining's multi_logloss: 0.152065\tvalid_1's multi_logloss: 0.156535\n",
            "[398]\ttraining's multi_logloss: 0.151792\tvalid_1's multi_logloss: 0.156262\n",
            "[399]\ttraining's multi_logloss: 0.151522\tvalid_1's multi_logloss: 0.155995\n",
            "[400]\ttraining's multi_logloss: 0.151255\tvalid_1's multi_logloss: 0.155734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('정확도 : ', accuracy_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C88b_WfNeVtW",
        "outputId": "e597c8b6-6b62-45ad-d2bc-8e6fd27e00a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 :  0.8650637246886913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HyperOpt를 이용한 하이퍼 파라미터 튜닝"
      ],
      "metadata": {
        "id": "nI5s25IxWfI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import hp\n",
        "\n",
        "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1),\n",
        "                    'min_child_weight':hp.quniform('min_child_weight',1,2,1),\n",
        "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1)}"
      ],
      "metadata": {
        "id": "jYFY6rm0WQd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6], got [1 2 3 4 5 6 7]\n",
        "\n",
        "* 해당 에러 발생으로 Label Encoder 사용"
      ],
      "metadata": {
        "id": "ebJ-sDrvYkc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train_over = le.fit_transform(y_train_over)\n",
        "\n",
        "#y_train = le.fit_transform(y_train) + over"
      ],
      "metadata": {
        "id": "Dwemtz66YtkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "from hyperopt import STATUS_OK\n",
        "\n",
        "def objective_func(search_space):\n",
        "\n",
        "  xgb_clf = XGBClassifier(n_estimators=50, max_depth=int(search_space['max_depth']),\n",
        "                          min_child_weight=int(search_space['min_child_weight']),\n",
        "                          learning_rate= search_space['colsample_bytree'],\n",
        "                          eval_metric='logloss')\n",
        "  accuracy = cross_val_score(xgb_clf, X_train_over, y_train_over, scoring='accuracy', cv=3)\n",
        "\n",
        "  return {'loss' :  -1*np.mean(accuracy), 'status' : STATUS_OK}"
      ],
      "metadata": {
        "id": "wLOmZfG4XdLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#최적 하이퍼 파라미터 도출\n",
        "from hyperopt import fmin, tpe, Trials\n",
        "\n",
        "trial_val = Trials()\n",
        "\n",
        "best = fmin(fn=objective_func,\n",
        "            space=xgb_search_space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=50,\n",
        "            trials=trial_val, rstate=np.random.default_rng(seed=9))\n",
        "print('best : ', best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "04jwuF5oX3_1",
        "outputId": "d9804080-8f3a-430f-a6aa-2b6f66947b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0%|          | 0/50 [04:12<?, ?trial/s, best loss=?]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-ec0e9c970f43>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrial_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m best = fmin(fn=objective_func, \n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_search_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    672\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             )\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-242feb0a9706>\u001b[0m in \u001b[0;36mobjective_func\u001b[0;34m(search_space)\u001b[0m\n\u001b[1;32m      9\u001b[0m                           \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'colsample_bytree'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                           eval_metric='logloss')\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_over\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_over\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m \u001b[0;34m:\u001b[0m  \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'status'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m             )\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m                                                     dtrain.handle))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_wrapper = XGBClassifier(n_estimators=400,\n",
        "                            learnings_rate=round(best['learning_rate'], 5),\n",
        "                            max_depth = int(best['max_depth']),\n",
        "                            min_child_weight = int(best['min_child_weight']),\n",
        "                            colsample_bytree=round(best['colsample_bytree'], 5))\n",
        "\n",
        "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
        "xgb_wrapper.fit(X_tr, y_tr, early_stopping_rounds  = 50, eval_metric='logloss',\n",
        "                eval_set=evals, verbose=True)\n",
        "\n",
        "preds = xgb_wrapper.predict(X_test)\n",
        "pred_proba = xgb_wrapper.predict_proba(X_test)[:,1]\n",
        "\n",
        "print('정확도 : ', accuracy_score(y_test, preds))\n",
        "print('F1 score : ', f1_score(y_test, preds))"
      ],
      "metadata": {
        "id": "-wIqsGnUX-j9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}