{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5N0a6b+LaSrU7aKHvXjlN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haeniKim/metaverse-academy/blob/master/DL/230703_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet\n",
        "\n",
        "* CNN 모델 중에서 많이 사용되는 모델"
      ],
      "metadata": {
        "id": "iE4kuUM8FxSF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2obvXqtFW1O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet의 Basic Block\n",
        "# input(저장) - 저장 합성곱 3 * 3 - 배치정규화 - ReLu - 합성곱 3 * 3 - 배치정규화 - skip connection(input으로 들어온 것과 더하는 과정)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_sizes = 3):\n",
        "    super(BasicBlock, self).__init__()\n",
        "\n",
        "    self.c1 = nn.Conv2d(in_channels, out_channels, kernel_size= kernel_sizes, padding = 1)\n",
        "    self.c2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_sizes, padding = 1)\n",
        "\n",
        "    #input의 3채널을 64에 맞춤.\n",
        "    self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size= 1) #정보를 그대로 저장, 정보 압축하지 않으려면 필터를 사용하지 않고, kernel_size 는 1로 설정\n",
        "\n",
        "    self.bn1 = nn.BatchNorm2d(num_features = out_channels)\n",
        "    self.bn2 = nn.BatchNorm2d(num_features = out_channels)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_ = x #입력으로 들어온 값 저장\n",
        "\n",
        "    x = self.c1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.c2(x)\n",
        "    x = self.bn2(x)\n",
        "\n",
        "    #skip connection\n",
        "    x_ = self.downsample(x_)\n",
        "    x += x_\n",
        "    x = self.relu(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "KrEmXTBTJ7NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* pytorch는 tensorflow와 달리 input이 자동으로 들어가지 않고, 값을 정해줘야 함."
      ],
      "metadata": {
        "id": "eEyAH0CBfJyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module): #원래 resnet은 17개 블록이 돌아감.  nn.Module -> 상\n",
        "  def __init__(self, num_classes = 10):\n",
        "    super(ResNet, self).__init__()\n",
        "\n",
        "    self.b1 = BasicBlock(in_channels = 3, out_channels= 64)\n",
        "    self.b2 = BasicBlock(in_channels = 64, out_channels = 128)\n",
        "    self.b3 = BasicBlock(in_channels = 128, out_channels = 256)\n",
        "\n",
        "    self.pool = nn.AvgPool2d(kernel_size = 2, stride = 2) #이미지 반으로 줄임.\n",
        "\n",
        "    #분류기\n",
        "    self.fc1 = nn.Linear(in_features = 4096, out_features = 2048)\n",
        "    self.fc2 = nn.Linear(in_features = 2048, out_features= 512)\n",
        "    self.fc3 = nn.Linear(in_features = 512, out_features = num_classes)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.b1(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.b2(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.b3(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    #평탄화\n",
        "    x = torch.flatten(x, start_dim = 1)\n",
        "\n",
        "    #분류\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "o-5QMMRqRb2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet(10)"
      ],
      "metadata": {
        "id": "7JQjRK80f1P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXZxUBPtfYtz",
        "outputId": "b5ca61b7-dc8c-45c9-cdab-061d7bc41eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "            Conv2d-6           [-1, 64, 32, 32]             256\n",
            "              ReLU-7           [-1, 64, 32, 32]               0\n",
            "        BasicBlock-8           [-1, 64, 32, 32]               0\n",
            "         AvgPool2d-9           [-1, 64, 16, 16]               0\n",
            "           Conv2d-10          [-1, 128, 16, 16]          73,856\n",
            "      BatchNorm2d-11          [-1, 128, 16, 16]             256\n",
            "             ReLU-12          [-1, 128, 16, 16]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]           8,320\n",
            "             ReLU-16          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-17          [-1, 128, 16, 16]               0\n",
            "        AvgPool2d-18            [-1, 128, 8, 8]               0\n",
            "           Conv2d-19            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-20            [-1, 256, 8, 8]             512\n",
            "             ReLU-21            [-1, 256, 8, 8]               0\n",
            "           Conv2d-22            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-23            [-1, 256, 8, 8]             512\n",
            "           Conv2d-24            [-1, 256, 8, 8]          33,024\n",
            "             ReLU-25            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-26            [-1, 256, 8, 8]               0\n",
            "        AvgPool2d-27            [-1, 256, 4, 4]               0\n",
            "================================================================\n",
            "Total params: 1,188,800\n",
            "Trainable params: 1,188,800\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 7.22\n",
            "Params size (MB): 4.53\n",
            "Estimated Total Size (MB): 11.77\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 팁\n",
        "\n",
        "* torchsummary의 summary를 이용해서 in_features 구하기\n",
        "* 예 `summary(model, (3, 32, 32))`"
      ],
      "metadata": {
        "id": "-8NJ-w-8aU_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* data load"
      ],
      "metadata": {
        "id": "VovOK9GtW2Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.optim.adam import Adam\n",
        "from torchvision.datasets.cifar import CIFAR10\n",
        "from torchvision.transforms import Compose, RandomCrop, RandomHorizontalFlip, Normalize\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "2GEUUCtJW3Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = Compose([\n",
        "    RandomCrop((32, 32), padding = 4),\n",
        "    RandomHorizontalFlip(p = 0.5),\n",
        "    T.ToTensor(),\n",
        "    Normalize(mean=(0.4914,0.4822,0.4465),std=(0.247,0.243,0.261))\n",
        "  ])"
      ],
      "metadata": {
        "id": "IArHr534XZEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CIFAR10(root = './', train = True, download = True, transform=transforms)\n",
        "test_data = CIFAR10(root = './', train = False, download = True, transform = transforms)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size = 32, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = 32, shuffle = False)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = ResNet(10)\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKvx98WtXyOK",
        "outputId": "24237697-d98f-4301-f58b-cf7d39469acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (b1): BasicBlock(\n",
              "    (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (downsample): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (b2): BasicBlock(\n",
              "    (c1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (downsample): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (b3): BasicBlock(\n",
              "    (c1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (downsample): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (fc1): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SummaryWriter 인스턴스 생성\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "id": "D-SW3L24ZuZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "lr = 1e-4\n",
        "\n",
        "optim = Adam(model.parameters(), lr = lr)\n",
        "\n",
        "for epoch in range(30):\n",
        "  for data, label in tqdm(train_loader):\n",
        "    optim.zero_grad()\n",
        "\n",
        "    preds = model(data.to(device))\n",
        "\n",
        "    loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "  print(f'epoch : {epoch+1}, loss : {loss.item()}')\n",
        "  #writer.add_scalar(\"Loss/train\", loss.item(), epoch+1)\n",
        "\n",
        "torch.save('cifar-resnet.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYGMi_urYhXk",
        "outputId": "da04c84b-bebb-4203-e753-d4ae866f00ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [24:12<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1, loss : 1.4115791320800781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [23:32<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 2, loss : 1.0136336088180542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [23:21<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 3, loss : 0.47634297609329224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [23:19<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 4, loss : 0.4536926746368408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [23:22<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 5, loss : 0.6580432057380676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [23:25<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 6, loss : 0.4621102213859558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [23:23<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 7, loss : 0.337603360414505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [23:24<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 8, loss : 0.6295395493507385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [23:24<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 9, loss : 0.4576990604400635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [23:26<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 10, loss : 0.5037466287612915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [23:26<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 11, loss : 0.48238715529441833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [23:25<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 12, loss : 0.555030107498169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 825/1563 [12:23<11:15,  1.09it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O_v-pvhuZ4-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<중요>\n",
        "\n",
        "* batch normalization을 사용하는 이유\n",
        "* skip connection을 하는 이유\n",
        "* down sampling을 하는 이유"
      ],
      "metadata": {
        "id": "j23ZpTlojt65"
      }
    }
  ]
}